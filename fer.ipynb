{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "### General imports ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from time import sleep\n",
    "import re\n",
    "import os\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "### Image processing ###\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.spatial import distance\n",
    "import imutils\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "\n",
    "### CNN models ###\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2#, activity_l2\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import models\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "### Build SVM models ###\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "\n",
    "### Same trained models ###\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Environment/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/envs/Environment/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reading the dataset\n",
    "dataset = pd.read_csv('fer2013.csv')\n",
    "\n",
    "#Obtaining train data where usage is \"Training\"\n",
    "train = dataset[dataset[\"Usage\"] == \"Training\"]\n",
    "\n",
    "#Obtaining test data where usage is \"PublicTest\"\n",
    "test = dataset[dataset[\"Usage\"] == \"PublicTest\"]\n",
    "\n",
    "#Converting \" \" separated pixel values to list\n",
    "train['pixels'] = train['pixels'].apply(lambda image_px : np.fromstring(image_px, sep = ' '))\n",
    "test['pixels'] = test['pixels'].apply(lambda image_px : np.fromstring(image_px, sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train and y_train is (28709, 48, 48, 1) and (28709, 1) respectively.\n",
      "Shape of X_test and y_test is (3589, 48, 48, 1) and (3589, 1) respectively.\n"
     ]
    }
   ],
   "source": [
    "shape_x = 48\n",
    "shape_y = 48\n",
    "\n",
    "X_train = train.iloc[:, 1].values\n",
    "y_train = train.iloc[:, 0].values\n",
    "X_test = test.iloc[:, 1].values\n",
    "y_test = test.iloc[:, 0].values\n",
    "\n",
    "#np.vstack stack arrays in sequence vertically (picking element row wise)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "#Reshape X_train, y_train,X_test,y_test in desired formats\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],48,48,1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],48,48,1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
    "\n",
    "print(\"Shape of X_train and y_train is \" + str(X_train.shape) +\" and \" + str(y_train.shape) +\" respectively.\")\n",
    "print(\"Shape of X_test and y_test is \" + str(X_test.shape) +\" and \" + str(y_test.shape) +\" respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to float datatype\n",
    "train_data = X_train.astype('float32')\n",
    "test_data = X_test.astype('float32')\n",
    "\n",
    "# Scale the data to lie between 0 to 1\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "\n",
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(y_train)\n",
    "test_labels_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  7\n",
      "Output classes :  [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    "\n",
    "# Find the shape of input images and create the variable input_shape\n",
    "nRows,nCols,nDims = X_train.shape[1:]\n",
    "input_shape = (nRows, nCols, nDims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining labels \n",
    "def get_label(argument):\n",
    "    labels = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad' , 5:'Surprise', 6:'Neutral'}\n",
    "    return(labels.get(argument, \"Invalid emotion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : Surprise')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.squeeze(X_train[25,:,:], axis = 2), cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(get_label(int(y_train[0]))))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(X_test[26,:,:], axis = 2), cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(get_label(int(y_test[1500]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    \n",
    "    #Cascade classifier pre-trained model\n",
    "    cascPath = '/usr/local/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "    \n",
    "    #BGR -> Gray conversion\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Cascade MultiScale classifier\n",
    "    detected_faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=6,\n",
    "                                                  minSize=(shape_x, shape_y),\n",
    "                                                  flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    coord = []\n",
    "    \n",
    "    for x, y, w, h in detected_faces :\n",
    "        if w > 100 :\n",
    "            sub_img=frame[y:y+h,x:x+w]\n",
    "            coord.append([x,y,w,h])\n",
    "    \n",
    "    return gray, detected_faces, coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_features(faces, offset_coefficients=(0.075, 0.05)):\n",
    "    gray = faces[0]\n",
    "    detected_face = faces[1]\n",
    "    \n",
    "    new_face = []\n",
    "    \n",
    "    for det in detected_face :\n",
    "        x, y, w, h = det\n",
    "        #Offset coefficient, np.floor takes the lowest integer (delete border of the image)\n",
    "        horizontal_offset = np.int(np.floor(offset_coefficients[0] * w))\n",
    "        vertical_offset = np.int(np.floor(offset_coefficients[1] * h))\n",
    "        \n",
    "        extracted_face = gray[y+vertical_offset:y+h, x+horizontal_offset:x-horizontal_offset+w]\n",
    "        new_extracted_face = zoom(extracted_face, (shape_x / extracted_face.shape[0],shape_y / extracted_face.shape[1]))\n",
    "        new_extracted_face = new_extracted_face.astype(np.float32)\n",
    "        #scale\n",
    "        new_extracted_face /= float(new_extracted_face.max())\n",
    "        #print(new_extracted_face)\n",
    "    \n",
    "        new_face.append(new_extracted_face)\n",
    "    \n",
    "    return new_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel3():\n",
    "    \n",
    "    #Model Initialization\n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(20, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(30, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(40, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(50, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(60, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(70, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(80, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(90, (3, 3), padding='same', activation='relu'))\n",
    "    \n",
    "    #Flattening\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Adding fully connected layer\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    \n",
    "    #Adding Output Layer\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer_outputs = [layer.output for layer in model.layers[:12]] \n",
    "# Extracts the outputs of the top 12 layers\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        zoom_range=0.2,          # randomly zoom into images\n",
    "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,    # randomly flip images\n",
    "        vertical_flip=False)     # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 684s 6s/step - loss: 1.8017 - accuracy: 0.2468 - val_loss: 1.8391 - val_accuracy: 0.2494\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 650s 6s/step - loss: 1.6628 - accuracy: 0.3369 - val_loss: 1.8284 - val_accuracy: 0.2494\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 592s 5s/step - loss: 1.5186 - accuracy: 0.4087 - val_loss: 1.8778 - val_accuracy: 0.2246\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 575s 5s/step - loss: 1.4280 - accuracy: 0.4407 - val_loss: 1.5735 - val_accuracy: 0.3940\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 993s 9s/step - loss: 1.3650 - accuracy: 0.4678 - val_loss: 1.4146 - val_accuracy: 0.4469\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 1218s 11s/step - loss: 1.3210 - accuracy: 0.4896 - val_loss: 1.2475 - val_accuracy: 0.5143\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 604s 5s/step - loss: 1.2817 - accuracy: 0.5064 - val_loss: 1.2175 - val_accuracy: 0.5302\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 698s 6s/step - loss: 1.2582 - accuracy: 0.5146 - val_loss: 1.2432 - val_accuracy: 0.5210\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 577s 5s/step - loss: 1.2383 - accuracy: 0.5258 - val_loss: 1.1664 - val_accuracy: 0.5531\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 577s 5s/step - loss: 1.2171 - accuracy: 0.5336 - val_loss: 1.2548 - val_accuracy: 0.5107\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 584s 5s/step - loss: 1.2023 - accuracy: 0.5384 - val_loss: 1.2084 - val_accuracy: 0.5425\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 678s 6s/step - loss: 1.1781 - accuracy: 0.5491 - val_loss: 1.1123 - val_accuracy: 0.5734\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 797s 7s/step - loss: 1.1689 - accuracy: 0.5521 - val_loss: 1.1378 - val_accuracy: 0.5651\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 696s 6s/step - loss: 1.1492 - accuracy: 0.5615 - val_loss: 1.1478 - val_accuracy: 0.5626\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 622s 6s/step - loss: 1.1411 - accuracy: 0.5663 - val_loss: 1.1307 - val_accuracy: 0.5776\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 552s 5s/step - loss: 1.1285 - accuracy: 0.5713 - val_loss: 1.1110 - val_accuracy: 0.5860\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 704s 6s/step - loss: 1.1126 - accuracy: 0.5738 - val_loss: 1.0968 - val_accuracy: 0.5938\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 575s 5s/step - loss: 1.1090 - accuracy: 0.5748 - val_loss: 1.0804 - val_accuracy: 0.5965\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 552s 5s/step - loss: 1.1003 - accuracy: 0.5813 - val_loss: 1.1387 - val_accuracy: 0.5717\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 556s 5s/step - loss: 1.0853 - accuracy: 0.5899 - val_loss: 1.0795 - val_accuracy: 0.5952\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 559s 5s/step - loss: 1.0776 - accuracy: 0.5926 - val_loss: 1.0775 - val_accuracy: 0.5960\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 543s 5s/step - loss: 1.0701 - accuracy: 0.5925 - val_loss: 1.1217 - val_accuracy: 0.5860\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 594s 5s/step - loss: 1.0641 - accuracy: 0.5921 - val_loss: 1.1470 - val_accuracy: 0.5740\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 567s 5s/step - loss: 1.0641 - accuracy: 0.5993 - val_loss: 1.0554 - val_accuracy: 0.6160\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 541s 5s/step - loss: 1.0540 - accuracy: 0.6028 - val_loss: 1.0543 - val_accuracy: 0.6082\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 553s 5s/step - loss: 1.0483 - accuracy: 0.6022 - val_loss: 1.1367 - val_accuracy: 0.5737\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 547s 5s/step - loss: 1.0504 - accuracy: 0.6040 - val_loss: 1.0524 - val_accuracy: 0.6030\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 544s 5s/step - loss: 1.0328 - accuracy: 0.6101 - val_loss: 1.0590 - val_accuracy: 0.6071\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 558s 5s/step - loss: 1.0323 - accuracy: 0.6074 - val_loss: 1.0448 - val_accuracy: 0.6077\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 547s 5s/step - loss: 1.0295 - accuracy: 0.6094 - val_loss: 1.0856 - val_accuracy: 0.6027\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 541s 5s/step - loss: 1.0174 - accuracy: 0.6134 - val_loss: 1.0406 - val_accuracy: 0.6149\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 541s 5s/step - loss: 1.0138 - accuracy: 0.6171 - val_loss: 1.1170 - val_accuracy: 0.5899\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 544s 5s/step - loss: 1.0147 - accuracy: 0.6188 - val_loss: 1.1278 - val_accuracy: 0.5971\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 540s 5s/step - loss: 0.9987 - accuracy: 0.6215 - val_loss: 1.0357 - val_accuracy: 0.6199\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 541s 5s/step - loss: 1.0047 - accuracy: 0.6197 - val_loss: 1.0639 - val_accuracy: 0.6021\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 977s 9s/step - loss: 0.9946 - accuracy: 0.6244 - val_loss: 1.0594 - val_accuracy: 0.6074\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 578s 5s/step - loss: 0.9986 - accuracy: 0.6193 - val_loss: 1.0620 - val_accuracy: 0.6055\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 567s 5s/step - loss: 0.9851 - accuracy: 0.6275 - val_loss: 1.0119 - val_accuracy: 0.6297\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 587s 5s/step - loss: 0.9825 - accuracy: 0.6264 - val_loss: 1.0412 - val_accuracy: 0.6163\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 561s 5s/step - loss: 0.9866 - accuracy: 0.6270 - val_loss: 1.0439 - val_accuracy: 0.6205\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 632s 6s/step - loss: 0.9785 - accuracy: 0.6310 - val_loss: 1.0370 - val_accuracy: 0.6211\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 638s 6s/step - loss: 0.9705 - accuracy: 0.6320 - val_loss: 1.0581 - val_accuracy: 0.6102\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 551s 5s/step - loss: 0.9644 - accuracy: 0.6335 - val_loss: 1.0240 - val_accuracy: 0.6205\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 547s 5s/step - loss: 0.9696 - accuracy: 0.6318 - val_loss: 1.0123 - val_accuracy: 0.6339\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 711s 6s/step - loss: 0.9665 - accuracy: 0.6337 - val_loss: 1.0671 - val_accuracy: 0.6094\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 626s 6s/step - loss: 0.9608 - accuracy: 0.6374 - val_loss: 1.0277 - val_accuracy: 0.6230\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 666s 6s/step - loss: 0.9510 - accuracy: 0.6411 - val_loss: 0.9931 - val_accuracy: 0.6275\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 676s 6s/step - loss: 0.9440 - accuracy: 0.6430 - val_loss: 1.0327 - val_accuracy: 0.6199\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 633s 6s/step - loss: 0.9457 - accuracy: 0.6409 - val_loss: 0.9974 - val_accuracy: 0.6339\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 649s 6s/step - loss: 0.9421 - accuracy: 0.6437 - val_loss: 1.0741 - val_accuracy: 0.6174\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 622s 6s/step - loss: 0.9381 - accuracy: 0.6434 - val_loss: 1.0678 - val_accuracy: 0.6144\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 627s 6s/step - loss: 0.9329 - accuracy: 0.6451 - val_loss: 1.0278 - val_accuracy: 0.6347\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 632s 6s/step - loss: 0.9248 - accuracy: 0.6517 - val_loss: 1.0154 - val_accuracy: 0.6328\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 646s 6s/step - loss: 0.9297 - accuracy: 0.6476 - val_loss: 1.0079 - val_accuracy: 0.6294\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 543s 5s/step - loss: 0.9280 - accuracy: 0.6462 - val_loss: 1.0108 - val_accuracy: 0.6230\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 542s 5s/step - loss: 0.9211 - accuracy: 0.6514 - val_loss: 1.0020 - val_accuracy: 0.6328\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 592s 5s/step - loss: 0.9170 - accuracy: 0.6523 - val_loss: 0.9792 - val_accuracy: 0.6383\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 599s 5s/step - loss: 0.9128 - accuracy: 0.6574 - val_loss: 1.0806 - val_accuracy: 0.6135\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 567s 5s/step - loss: 0.9095 - accuracy: 0.6542 - val_loss: 1.0355 - val_accuracy: 0.6266\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 538s 5s/step - loss: 0.9025 - accuracy: 0.6600 - val_loss: 1.0333 - val_accuracy: 0.6278\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 560s 5s/step - loss: 0.9085 - accuracy: 0.6544 - val_loss: 1.0081 - val_accuracy: 0.6372\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 534s 5s/step - loss: 0.8949 - accuracy: 0.6617 - val_loss: 1.0557 - val_accuracy: 0.6266\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 536s 5s/step - loss: 0.8997 - accuracy: 0.6620 - val_loss: 1.0213 - val_accuracy: 0.6347\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 588s 5s/step - loss: 0.8959 - accuracy: 0.6587 - val_loss: 1.0033 - val_accuracy: 0.6392\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 544s 5s/step - loss: 0.8955 - accuracy: 0.6602 - val_loss: 0.9696 - val_accuracy: 0.6523\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 561s 5s/step - loss: 0.8954 - accuracy: 0.6609 - val_loss: 1.0173 - val_accuracy: 0.6336\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 542s 5s/step - loss: 0.8921 - accuracy: 0.6628 - val_loss: 1.0730 - val_accuracy: 0.6233\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 539s 5s/step - loss: 0.8828 - accuracy: 0.6639 - val_loss: 1.0072 - val_accuracy: 0.6489\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 538s 5s/step - loss: 0.8862 - accuracy: 0.6639 - val_loss: 1.0011 - val_accuracy: 0.6350\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 565s 5s/step - loss: 0.8779 - accuracy: 0.6659 - val_loss: 1.0397 - val_accuracy: 0.6261\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 545s 5s/step - loss: 0.8760 - accuracy: 0.6651 - val_loss: 1.0326 - val_accuracy: 0.6258\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 570s 5s/step - loss: 0.8736 - accuracy: 0.6706 - val_loss: 1.0163 - val_accuracy: 0.6484\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 563s 5s/step - loss: 0.8696 - accuracy: 0.6707 - val_loss: 1.0294 - val_accuracy: 0.6319\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 590s 5s/step - loss: 0.8798 - accuracy: 0.6678 - val_loss: 1.0254 - val_accuracy: 0.6375\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 541s 5s/step - loss: 0.8674 - accuracy: 0.6731 - val_loss: 1.0409 - val_accuracy: 0.6202\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 537s 5s/step - loss: 0.8623 - accuracy: 0.6728 - val_loss: 1.0564 - val_accuracy: 0.6241\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 561s 5s/step - loss: 0.8569 - accuracy: 0.6741 - val_loss: 1.0042 - val_accuracy: 0.6297\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 564s 5s/step - loss: 0.8456 - accuracy: 0.6829 - val_loss: 0.9980 - val_accuracy: 0.6414\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 550s 5s/step - loss: 0.8488 - accuracy: 0.6742 - val_loss: 1.0392 - val_accuracy: 0.6336\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 538s 5s/step - loss: 0.8382 - accuracy: 0.6829 - val_loss: 1.0771 - val_accuracy: 0.6283\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 539s 5s/step - loss: 0.8474 - accuracy: 0.6807 - val_loss: 1.0412 - val_accuracy: 0.6333\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 544s 5s/step - loss: 0.8392 - accuracy: 0.6779 - val_loss: 1.0296 - val_accuracy: 0.6319\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 544s 5s/step - loss: 0.8489 - accuracy: 0.6764 - val_loss: 1.0430 - val_accuracy: 0.6325\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 537s 5s/step - loss: 0.8307 - accuracy: 0.6826 - val_loss: 1.0285 - val_accuracy: 0.6381\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 544s 5s/step - loss: 0.8348 - accuracy: 0.6826 - val_loss: 1.0986 - val_accuracy: 0.6261\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 539s 5s/step - loss: 0.8382 - accuracy: 0.6820 - val_loss: 1.0871 - val_accuracy: 0.6247\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 541s 5s/step - loss: 0.8245 - accuracy: 0.6883 - val_loss: 1.0612 - val_accuracy: 0.6475\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 548s 5s/step - loss: 0.8309 - accuracy: 0.6860 - val_loss: 1.0210 - val_accuracy: 0.6408\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 561s 5s/step - loss: 0.8279 - accuracy: 0.6882 - val_loss: 1.0491 - val_accuracy: 0.6378\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 545s 5s/step - loss: 0.8140 - accuracy: 0.6904 - val_loss: 1.0830 - val_accuracy: 0.6272\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 540s 5s/step - loss: 0.8200 - accuracy: 0.6893 - val_loss: 1.0157 - val_accuracy: 0.6381\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 548s 5s/step - loss: 0.8183 - accuracy: 0.6908 - val_loss: 1.0390 - val_accuracy: 0.6350\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 542s 5s/step - loss: 0.8116 - accuracy: 0.6897 - val_loss: 1.1305 - val_accuracy: 0.6205\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 542s 5s/step - loss: 0.8061 - accuracy: 0.6963 - val_loss: 1.0770 - val_accuracy: 0.6328\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 542s 5s/step - loss: 0.8010 - accuracy: 0.6987 - val_loss: 1.0599 - val_accuracy: 0.6461\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 544s 5s/step - loss: 0.8011 - accuracy: 0.6987 - val_loss: 1.0514 - val_accuracy: 0.6434\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 541s 5s/step - loss: 0.8019 - accuracy: 0.6964 - val_loss: 1.0159 - val_accuracy: 0.6506\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 568s 5s/step - loss: 0.7971 - accuracy: 0.7006 - val_loss: 1.0382 - val_accuracy: 0.6408\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 550s 5s/step - loss: 0.7973 - accuracy: 0.6980 - val_loss: 1.0352 - val_accuracy: 0.6473\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 543s 5s/step - loss: 0.7863 - accuracy: 0.7008 - val_loss: 1.1647 - val_accuracy: 0.6239\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size),\n",
    "    steps_per_epoch=int(np.ceil(train_data.shape[0] / float(batch_size))),\n",
    "    epochs = epochs, \n",
    "    validation_data=(test_data, test_labels_one_hot)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5d59026e3541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfer_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fer.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfer_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fer.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.25\n",
    "frame_check = 20\n",
    "face_detect = dlib.get_frontal_face_detector()\n",
    "predictor_landmarks = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "(jStart, jEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"jaw\"]\n",
    "\n",
    "(eblStart, eblEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "(ebrStart, ebrEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiredLeftEye=(0.35, 0.35)\n",
    "\n",
    "def align(gray, rect):\n",
    "    # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = shape_to_np(shape)\n",
    " \n",
    "    # extract the left and right eye (x, y)-coordinates\n",
    "    (lStart, lEnd) = FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rStart, rEnd) = FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    leftEyePts = shape[lStart:lEnd]\n",
    "    rightEyePts = shape[rStart:rEnd]\n",
    "        \n",
    "    # compute the center of mass for each eye\n",
    "    leftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n",
    "    rightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n",
    " \n",
    "    # compute the angle between the eye centroids\n",
    "    dY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "    dX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "    angle = np.degrees(np.arctan2(dY, dX)) - 180\n",
    "        \n",
    "    # compute the desired right eye x-coordinate based on the\n",
    "    # desired x-coordinate of the left eye\n",
    "    desiredRightEyeX = 1.0 - desiredLeftEye[0]\n",
    " \n",
    "    # determine the scale of the new resulting image by taking\n",
    "    # the ratio of the distance between eyes in the *current*\n",
    "    # image to the ratio of distance between eyes in the\n",
    "    # *desired* image\n",
    "    dist = np.sqrt((dX ** 2) + (dY ** 2))\n",
    "    desiredDist = (desiredRightEyeX - desiredLeftEye[0])\n",
    "    desiredDist *= self.desiredFaceWidth\n",
    "    scale = desiredDist / dist\n",
    "        \n",
    "    # compute center (x, y)-coordinates (i.e., the median point)\n",
    "    # between the two eyes in the input image\n",
    "    eyesCenter = ((leftEyeCenter[0] + rightEyeCenter[0]) // 2,\n",
    "            (leftEyeCenter[1] + rightEyeCenter[1]) // 2)\n",
    " \n",
    "    # grab the rotation matrix for rotating and scaling the face\n",
    "    M = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n",
    " \n",
    "    # update the translation component of the matrix\n",
    "    tX = self.desiredFaceWidth * 0.5\n",
    "    tY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
    "    M[0, 2] += (tX - eyesCenter[0])\n",
    "    M[1, 2] += (tY - eyesCenter[1])\n",
    "        \n",
    "    # apply the affine transformation\n",
    "    (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
    "    #output = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    output = cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    # return the aligned face\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lancer la capture video\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "flag = 0\n",
    "j = 1\n",
    "#load model\n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "#load weights\n",
    "model.load_weights('fer.h5')\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    face_index = 0\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = face_detect(gray, 1)\n",
    "    #gray, detected_faces, coord = detect_face(frame)\n",
    "    \n",
    "    for (i, rect) in enumerate(rects):\n",
    "        \n",
    "        shape = predictor_landmarks(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        face = gray[y:y+h,x:x+w]\n",
    "        \n",
    "        #Zoom sur la face extraite\n",
    "        face = zoom(face, (shape_x / face.shape[0],shape_y / face.shape[1]))\n",
    "        #cast type float\n",
    "        face = face.astype(np.float32)\n",
    "        #scale\n",
    "        face /= float(face.max())\n",
    "        face = np.reshape(face.flatten(), (1, 48, 48, 1))\n",
    "        prediction = model.predict(face)\n",
    "        prediction_result = np.argmax(prediction)\n",
    "        \n",
    "        # Rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "        cv2.putText(frame, \"Face #{}\".format(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    " \n",
    "        for (j, k) in shape:\n",
    "            cv2.circle(frame, (j, k), 1, (0, 0, 255), -1)\n",
    "\n",
    "         # 12. Add prediction probabilities\n",
    "            cv2.putText(frame, \"Emotional report : \",(40,120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "            cv2.putText(frame, \"Angry : \" + str(round(prediction[0][0],3)),(40,140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "            cv2.putText(frame, \"Disgust : \" + str(round(prediction[0][1],3)),(40,160), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "            cv2.putText(frame, \"Fear : \" + str(round(prediction[0][2],3)),(40,180), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Happy : \" + str(round(prediction[0][3],3)),(40,200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Sad : \" + str(round(prediction[0][4],3)),(40,220), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Surprise : \" + str(round(prediction[0][5],3)),(40,240), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Neutral : \" + str(round(prediction[0][6],3)),(40,260), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        \n",
    "        # draw extracted face in the top right corner\n",
    "        frame[face_index * shape_x: (face_index + 1) * shape_x, -1 * shape_y - 1:-1, :] = cv2.cvtColor(face * 255, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # 13. Annotate main image with a label\n",
    "        if prediction_result == 0 :\n",
    "                cv2.putText(frame, \"Angry\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif prediction_result == 1 :\n",
    "                cv2.putText(frame, \"Disgust\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif prediction_result == 2 :\n",
    "                cv2.putText(frame, \"Fear\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif prediction_result == 3 :\n",
    "                cv2.putText(frame, \"Happy\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif prediction_result == 4 :\n",
    "                cv2.putText(frame, \"Sad\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif prediction_result == 5 :\n",
    "                cv2.putText(frame, \"Surprise\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        else :\n",
    "                cv2.putText(frame, \"Neutral\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "                   \n",
    "        \n",
    "        # 5. Eye Detection and Blink Count\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        \n",
    "        # Compute Eye Aspect Ratio\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "            \n",
    "        # And plot its contours\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "        # Compute total blinks and frequency\n",
    "        if ear < thresh:\n",
    "            flag += 1\n",
    "            #cv2.putText(frame, \"Blink\", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        \n",
    "        cv2.putText(frame, \"Total blinks : \" + str(flag), (40, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, 155, 1)\n",
    "        #cv2.putText(frame, \"Blink Frequency : \" + str(int(flag/j)), (40, 220), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        \n",
    "        # 6. Detect Nose\n",
    "        nose = shape[nStart:nEnd]\n",
    "        noseHull = cv2.convexHull(nose)\n",
    "        cv2.drawContours(frame, [noseHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "        # 7. Detect Mouth\n",
    "        mouth = shape[mStart:mEnd]\n",
    "        mouthHull = cv2.convexHull(mouth)\n",
    "        cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "        # 8. Detect Jaw\n",
    "        jaw = shape[jStart:jEnd]\n",
    "        jawHull = cv2.convexHull(jaw)\n",
    "        cv2.drawContours(frame, [jawHull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "        # 9. Detect Eyebrows\n",
    "        ebr = shape[ebrStart:ebrEnd]\n",
    "        ebrHull = cv2.convexHull(ebr)\n",
    "        cv2.drawContours(frame, [ebrHull], -1, (0, 255, 0), 1)\n",
    "        ebl = shape[eblStart:eblEnd]\n",
    "        eblHull = cv2.convexHull(ebl)\n",
    "        cv2.drawContours(frame, [eblHull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "        cv2.putText(frame,'Number of Faces : ' + str(i+1),(40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, 155, 1)\n",
    "        j = j + 1\n",
    "        cv2.imshow('Video', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
